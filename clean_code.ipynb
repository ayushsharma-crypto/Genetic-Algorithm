{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wrong-fitting",
   "metadata": {},
   "source": [
    "# Machine, Data & Learning\n",
    "\n",
    "## Project | Genetic Algorithm\n",
    "\n",
    "Team 30 | Tribrid\n",
    "-----------\n",
    "* Nitin Chandak (2019101024)\n",
    "* Ayush Sharma (2019101004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "compatible-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usefull Imports\n",
    "import client as server\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-prefix",
   "metadata": {},
   "source": [
    "### Default Initial Overfit Vector\n",
    "```\n",
    "[\n",
    "    0.0, \n",
    "    -1.45799022e-12, \n",
    "    -2.28980078e-13,  \n",
    "    4.62010753e-11, \n",
    "    -1.75214813e-10, \n",
    "    -1.83669770e-15,  \n",
    "    8.52944060e-16,  \n",
    "    2.29423303e-05, \n",
    "    -2.04721003e-06, \n",
    "    -1.59792834e-08,  \n",
    "    9.98214034e-10\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "vanilla-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usefull Global Constants & lambda functions\n",
    "\n",
    "TEAM_ID = 'colthAUIKUTfdh4qWrnHBhJzkyEm8kt4qIue1BKtyvLItfp8Po'\n",
    "\n",
    "DEFAULT_INITIAL_OVERFIT_VECTOR = [\n",
    "    0.0, \n",
    "    -1.45799022e-12, \n",
    "    -2.28980078e-13,  \n",
    "    4.62010753e-11, \n",
    "    -1.75214813e-10, \n",
    "    -1.83669770e-15,  \n",
    "    8.52944060e-16,  \n",
    "    2.29423303e-05, \n",
    "    -2.04721003e-06, \n",
    "    -1.59792834e-08,  \n",
    "    9.98214034e-10\n",
    "]\n",
    "\n",
    "POPULATION_SIZE = 10 # intentionaly chose this as we have to store 10 best vectors\n",
    "GENERATION_LOOP = 10\n",
    "MIN_GENE_VAL = -10\n",
    "MAX_GENE_VAL = 10\n",
    "MUTATION_PROBABILITY = 0.5\n",
    "MUTATION_FACTOR = lambda : random.uniform(0.9, 1.1)\n",
    "MATING_POOL_SIZE = 6\n",
    "\n",
    "OUTPUT_FILE = 'output.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "governmental-scratch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_output_file(fileName):\n",
    "    '''\n",
    "    This funtion returns False if \n",
    "    filename exist  otherwise True\n",
    "    '''\n",
    "    return os.path.exists(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "respected-large",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_file(filename):\n",
    "    '''\n",
    "    This function checks existence of file\n",
    "    filename and if exist then checks if it\n",
    "    empty or not.\n",
    "    '''\n",
    "    if is_output_file(filename):\n",
    "        return (os.stat(filename).st_size != 0)\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "grave-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_default_output_file():\n",
    "    '''\n",
    "    This function will create a default\n",
    "    output file for dumping our 10 best vector\n",
    "    before any iteration of algorithm when called.\n",
    "    '''\n",
    "    answer = []\n",
    "    for i in range(10):\n",
    "        ret_vector = DEFAULT_INITIAL_OVERFIT_VECTOR.copy()\n",
    "        for j in range(len(ret_vector)):\n",
    "            if random.randint(1,10)<(10*MUTATION_PROBABILITY):\n",
    "                if ret_vector[j]==0:\n",
    "                    ret_vector[j]=random.randint(-10,10)\n",
    "                else:\n",
    "                    new_gene = ret_vector[j]*MUTATION_FACTOR()\n",
    "                    if abs(new_gene)<10:\n",
    "                        ret_vector[j]=new_gene\n",
    "        answer.append(ret_vector)\n",
    "    with open(OUTPUT_FILE,'w') as write_file:\n",
    "        json.dump(answer, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "apart-genre",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_output_file():\n",
    "    '''\n",
    "    This function will read the OUTPUT_FILE\n",
    "    and return the answer array there which \n",
    "    contains 10 best vector obtained so far.\n",
    "    '''\n",
    "    with open(OUTPUT_FILE,'r') as write_file:\n",
    "        answer=json.load(write_file)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "banned-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_best_vectors(answer: list):\n",
    "    '''\n",
    "    This function will dump the list of\n",
    "    10 vectors into the OUTPUT_FILE file.\n",
    "    And return the updated data.\n",
    "    '''\n",
    "    with open(OUTPUT_FILE,'w') as write_file:\n",
    "        json.dump(answer, write_file)\n",
    "    return read_output_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "fixed-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@TODO: Within While loop:\n",
    "#       Generate new Population\n",
    "#       Get errors, fitness & curr_weight_distribution\n",
    "#       Update 10 best vector array i.e. make a separate list for it.\n",
    "#       Keep track of generations of the vecotrs for generation folder.\n",
    "#       Dump 10 best vectors into output.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "greenhouse-angola",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_both_err(population):\n",
    "    '''\n",
    "    This function utilises the API \n",
    "    call provided to us for getting the\n",
    "    errors on the vectors within the population.\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    population: list of vector of 11-D\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    It returns two list train_err & validation_err\n",
    "    which are errors for the given poplation's vectors.\n",
    "    '''\n",
    "    train_err = [ random.randint(1,300) for i in range(len(population))]\n",
    "    validation_err = [ random.randint(1,300) for i in range(len(population))]\n",
    "    \n",
    "#     train_err = []\n",
    "#     validation_err = []\n",
    "#     for individual in population:\n",
    "#         [te, ve]= server.get_errors(TEAM_ID,individual)\n",
    "#         train_err.append(te)\n",
    "#         validation_err.append(ve)\n",
    "    return train_err, validation_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "automated-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost(train_error, validation_error):\n",
    "    '''\n",
    "    This function calculates the cost\n",
    "    for given list of errors. Lower the\n",
    "    cost more fit/perfect the vector.\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    Requires two list train_err & validation_err\n",
    "    which are errors for the given poplation's vectors.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    Returns the list of fitness for corresponding errors.\n",
    "    '''\n",
    "    cost = []\n",
    "    for i in range(len(train_error)):\n",
    "        sum_err = train_error[i] + validation_error[i]\n",
    "        abs_diff_err = abs(train_error[i] - validation_error[i])\n",
    "        fit = sum_err + 2 * abs_diff_err\n",
    "        cost.append(fit)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "adapted-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_population_info():\n",
    "    '''\n",
    "    This function will return a stack\n",
    "    of all the 10 best vector along with\n",
    "    their Train error, Validation error\n",
    "    and their cost\n",
    "    '''\n",
    "    initial_population = read_output_file()\n",
    "    train_error, validation_error = get_both_err(initial_population)\n",
    "    initial_cost = get_cost(train_error, validation_error)\n",
    "    initial_population_info = np.column_stack((initial_population,train_error, validation_error,initial_cost))\n",
    "    return initial_population_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "minute-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mating_population(parent_population):\n",
    "    '''\n",
    "    This function will select top MATING_POOL_SIZE\n",
    "    individuals with least costs from the parent_population \n",
    "    for cross-over.\n",
    "    '''\n",
    "    mating_pool = parent_population[:MATING_POOL_SIZE]\n",
    "    return mating_pool    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "competent-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_over(p1,p2):\n",
    "    '''\n",
    "    This function simply does the cross-over\n",
    "    on two individual p1,p2 and returns c1,c2\n",
    "    i.e. crossed-child.\n",
    "    '''\n",
    "    crossover_point = random.randint(1, 10)\n",
    "    c1 = list(p1[:crossover_point]) + list(p2[crossover_point:])\n",
    "    c2 = list(p2[:crossover_point]) + list(p1[crossover_point:])\n",
    "    return c1, c2\n",
    "\n",
    "def simulate_cross_over(mating_population):\n",
    "    '''\n",
    "    This function will perform the cross-over\n",
    "    on mating_population and generate POPULATION_SIZE\n",
    "    total childs/individual.\n",
    "    '''\n",
    "    mating_population = mating_population[:,:-3]\n",
    "    crossed_population = []\n",
    "    for i in range(POPULATION_SIZE//2):\n",
    "        p1 = mating_population[random.randint(0,MATING_POOL_SIZE-1)]\n",
    "        p2 = mating_population[random.randint(0,MATING_POOL_SIZE-1)]\n",
    "        c1, c2 = cross_over(p1,p2)\n",
    "        crossed_population.append(c1)\n",
    "        crossed_population.append(c2)\n",
    "    return crossed_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "cosmetic-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_population(crossed_population):\n",
    "    '''\n",
    "    This function will mutate the crossed_population\n",
    "    and returns the mutated population.\n",
    "    '''\n",
    "    mutated_population = []\n",
    "    for i in range(len(crossed_population)):\n",
    "        curr_population = crossed_population[i]\n",
    "        for j in range(len(curr_population)):\n",
    "            if random.randint(1, 10) <= (10*MUTATION_PROBABILITY):\n",
    "                new_gene = curr_population[j]*MUTATION_FACTOR()\n",
    "                if abs(new_gene)<=10:\n",
    "                    curr_population[j]=new_gene\n",
    "        mutated_population.append(curr_population)\n",
    "    return mutated_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "polyphonic-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_next_generation(mutated_population,parent_population_info):\n",
    "    '''\n",
    "    This funtion will get the errors & cost for the mutated population\n",
    "    then sort it in increasing order. The next_generation will be the \n",
    "    combination of 3 top parent & (POPULATION_SIZE-3) mutated childs.\n",
    "    '''\n",
    "    train_err, validation_err = get_both_err(mutated_population)\n",
    "    mutated_cost = get_cost(train_err, validation_err)\n",
    "    mutated_population_info = np.column_stack((mutated_population,train_err, validation_err,mutated_cost))\n",
    "    mutated_population_info = mutated_population_info[np.argsort(mutated_population_info[:,-1])]\n",
    "    \n",
    "    select_parent = parent_population_info[:3]\n",
    "    select_mutated = mutated_population_info[:(POPULATION_SIZE-3)]\n",
    "    \n",
    "    next_generation = np.concatenate((select_parent,select_mutated))\n",
    "    next_generation = next_generation[np.argsort(next_generation[:,-1])]\n",
    "    return next_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "funded-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_vector(vector: list):\n",
    "    '''\n",
    "    This function has been written for submitting the best\n",
    "    vector generated so far for intermediate evaluation.\n",
    "    `vector` is a list of length 14 with last three\n",
    "    data as train_err, validation_err & cost.\n",
    "    '''\n",
    "    print(vector)\n",
    "    submit_vector = vector[:-3]\n",
    "    response = server.submit(TEAM_ID,submit_vector.tolist())\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "bigger-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_best_vector_set(next_generation,best_vector_set):\n",
    "    '''\n",
    "    This function will merge next_generation \n",
    "    & best_vector_set in increasing order of cost.\n",
    "    Then return the top 10 vectors from it.\n",
    "    '''\n",
    "    new_best_vector_set = np.concatenate((next_generation,best_vector_set))\n",
    "    k = new_best_vector_set[np.argsort(new_best_vector_set[:,-1])].tolist()\n",
    "    new_best_vector_set = [k for k,_ in itertools.groupby(k)]\n",
    "    new_best_vector_set = np.array(new_best_vector_set)\n",
    "    return new_best_vector_set[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "electric-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA():\n",
    "    '''\n",
    "    Main function to be called to run\n",
    "    the implemented genetic algorithm.\n",
    "    '''\n",
    "    if not is_valid_file(OUTPUT_FILE):\n",
    "        create_default_output_file()\n",
    "        print('created a new output.txt')\n",
    "    \n",
    "    all_generation = []       \n",
    "    initial_population_info = get_initial_population_info()\n",
    "    parent_population = initial_population_info[np.argsort(initial_population_info[:,-1])]\n",
    "    best_vector_set = parent_population\n",
    "    \n",
    "    for generation in range(GENERATION_LOOP-1):\n",
    "        \n",
    "        mating_population = create_mating_population(parent_population)\n",
    "        crossed_population = simulate_cross_over(mating_population)\n",
    "        mutated_population = mutate_population(crossed_population)\n",
    "        next_generation = create_next_generation(mutated_population,parent_population)\n",
    "        best_vector_set = update_best_vector_set(next_generation,best_vector_set)\n",
    "        \n",
    "        reproduction_info_dict = {\n",
    "            'parent_population': parent_population[:,:-3],\n",
    "            'error': parent_population[:,-3:-1],\n",
    "            'cost': parent_population[:,-1:],\n",
    "            'mating_population' : mating_population,\n",
    "            'crossed_population' : np.array(crossed_population),\n",
    "            'mutated_population' : np.array(mutated_population),\n",
    "            'next_generation' : next_generation[:,:-3],\n",
    "            'next_error': next_generation[:,-3:-1],\n",
    "            'next_cost': next_generation[:,-1:]\n",
    "        }\n",
    "        all_generation.append(reproduction_info_dict)\n",
    "        parent_population = next_generation\n",
    "    return best_vector_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "developmental-vessel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created a new output.txt\n",
      "[[-9.85788281e+00 -1.61129421e-12 -2.15513714e-13  4.73092182e-11\n",
      "  -1.84099723e-10 -2.36467711e-15  9.06554179e-16  2.32614407e-05\n",
      "  -1.78678093e-06 -1.56316135e-08  8.11201855e-10  1.90000000e+01\n",
      "   7.00000000e+00  5.00000000e+01]\n",
      " [-9.72424007e+00 -1.70305982e-12 -2.20221129e-13  4.55677031e-11\n",
      "  -1.84099723e-10 -1.76079261e-15  9.22712135e-16  2.35954979e-05\n",
      "  -2.21379245e-06 -1.52170610e-08  1.02863632e-09  2.60000000e+01\n",
      "   5.50000000e+01  1.39000000e+02]\n",
      " [-8.98083009e+00 -1.61129421e-12 -2.20221129e-13  4.55677031e-11\n",
      "  -1.84099723e-10 -1.92151204e-15  1.01072083e-15  2.51712461e-05\n",
      "  -2.25727505e-06 -1.63212033e-08  1.14218609e-09  7.40000000e+01\n",
      "   8.50000000e+01  1.81000000e+02]\n",
      " [-9.00000000e+00 -1.61129421e-12 -2.20381430e-13  4.62010753e-11\n",
      "  -1.75214813e-10 -1.74132296e-15  8.13723584e-16  2.29423303e-05\n",
      "  -2.04721003e-06 -1.57525118e-08  1.06951609e-09  7.20000000e+01\n",
      "   8.60000000e+01  1.86000000e+02]\n",
      " [-9.00000000e+00 -1.61129421e-12 -2.60845576e-13  3.98131956e-11\n",
      "  -1.77314390e-10 -1.58334026e-15  8.12727126e-16  2.27168166e-05\n",
      "  -2.04721003e-06 -1.42025865e-08  1.06951609e-09  9.10000000e+01\n",
      "   9.60000000e+01  1.97000000e+02]\n",
      " [-9.58032196e+00 -1.84652017e-12 -1.99590853e-13  4.55677031e-11\n",
      "  -1.86613889e-10 -1.63850580e-15  1.01406271e-15  2.35954979e-05\n",
      "  -1.92219222e-06 -1.47018457e-08  8.85471413e-10  9.10000000e+01\n",
      "   6.00000000e+01  2.13000000e+02]\n",
      " [-9.38414802e+00 -1.58692315e-12 -2.18455756e-13  5.10968170e-11\n",
      "  -1.84099723e-10 -2.36408024e-15  9.06554179e-16  2.32614407e-05\n",
      "  -2.42897766e-06 -1.52170610e-08  1.02863632e-09  9.30000000e+01\n",
      "   4.70000000e+01  2.32000000e+02]\n",
      " [-9.85788281e+00 -1.61129421e-12 -2.41743779e-13  4.13431512e-11\n",
      "  -1.77314390e-10 -1.58041867e-15  8.12727126e-16  2.09388586e-05\n",
      "  -2.04721003e-06 -1.57525118e-08  1.06951609e-09  5.60000000e+01\n",
      "   9.70000000e+01  2.35000000e+02]\n",
      " [ 0.00000000e+00 -1.46879466e-12 -2.24199830e-13  5.21334344e-11\n",
      "  -1.68976514e-10 -1.92151204e-15  9.22712135e-16  2.35954979e-05\n",
      "  -2.04721003e-06 -1.52170610e-08  9.71003494e-10  3.90000000e+01\n",
      "   9.60000000e+01  2.49000000e+02]\n",
      " [ 0.00000000e+00 -1.37568559e-12 -2.28980078e-13  4.62010753e-11\n",
      "  -1.75214813e-10 -1.92151204e-15  8.52944060e-16  2.35954979e-05\n",
      "  -2.04721003e-06 -1.59792834e-08  8.99668997e-10  1.04000000e+02\n",
      "   1.28000000e+02  2.80000000e+02]]\n"
     ]
    }
   ],
   "source": [
    "best_vector_set = GA()\n",
    "print(best_vector_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "adapted-washington",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-541-f6a4079d3f6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Before =>\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_output_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdump_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_vector_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdump_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdump_best_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdump_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"After =>\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_output_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-514-48438cf66b38>\u001b[0m in \u001b[0;36mread_output_file\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     '''\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwrite_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0manswer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "print(\"Before =>\\n\",np.array(read_output_file()))\n",
    "dump_data = best_vector_set[:,:-3]\n",
    "print(dump_data)\n",
    "dump_best_vectors(dump_data.tolist())\n",
    "print(\"After =>\\n\",np.array(read_output_file()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-recorder",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
